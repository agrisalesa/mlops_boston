name: MLOps CI/CD Pipeline

on:
  push:
    branches: [ "main" ]
  workflow_dispatch:
    inputs:
      force_retrain:
        description: "Forzar retraining (true/false)"
        required: false
        default: "false"

permissions:
  contents: read
  packages: write

jobs:
  build-train-test:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install xgboost scipy pytest pytest-cov

      - name: Run provenance tracking
        run: python scripts/00_provenance.py

      - name: Validate & clean data
        run: python scripts/01_validar_datos.py

      - name: Train baseline models
        run: python scripts/02_train_baseline.py

      - name: Unit tests
        run: pytest -q

      - name: Coverage report (XML + Terminal)
        run: |
          # Genera coverage.xml en la RAÍZ (lo espera Sonar)
          pytest --cov=scripts --cov-report=term-missing --cov-report=xml --no-cov-on-fail

      - name: Coverage summary
        run: |
          echo "### Code Coverage Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Script | Stmts | Miss | Cover |" >> $GITHUB_STEP_SUMMARY
          echo "|---------|-------|-------|--------|" >> $GITHUB_STEP_SUMMARY
          pytest --cov=scripts --cov-report=term-missing --cov-report=xml --no-cov-on-fail \
            | grep -E "scripts/.*py|TOTAL" \
            | awk '{
                if ($1 == "TOTAL") {
                  printf("| **%s** | **%s** | **%s** | **%s** |\n", $1, $2, $3, $4)
                } else {
                  printf("| %s | %s | %s | %s |\n", $1, $2, $3, $4)
                }
              }' >> $GITHUB_STEP_SUMMARY

      - name: Upload coverage artifact
        uses: actions/upload-artifact@v4
        with:
          name: coverage-report
          path: coverage.xml

      - name: Upload model artifacts
        uses: actions/upload-artifact@v4
        with:
          name: model-artifacts
          path: |
            models/
            data/processed/housing_clean.csv
            data/provenance.json

  sonarcloud-analysis:
    needs: build-train-test
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Required for accurate analysis

      - name: Setup JDK 17 (required by SonarScanner)
        uses: actions/setup-java@v4
        with:
          distribution: 'zulu'
          java-version: '17'

      - name: Download coverage report
        uses: actions/download-artifact@v4
        with:
          name: coverage-report
          path: .  # deja coverage.xml en la raíz

      - name: Cache SonarCloud packages
        uses: actions/cache@v4
        with:
          path: ~/.sonar/cache
          key: ${{ runner.os }}-sonar
          restore-keys: ${{ runner.os }}-sonar

      - name: Verify coverage presence
        run: |
          ls -l .
          test -f coverage.xml || (echo "coverage.xml not found"; exit 1)

      - name: Run SonarCloud Scan
        uses: SonarSource/sonarcloud-github-action@v2
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
        with:
          # 👉 fuerza a Sonar a leer el coverage que acabamos de descargar
          args: >
            -Dsonar.python.coverage.reportPaths=coverage.xml
            -Dsonar.sourceEncoding=UTF-8

      - name: Link to SonarCloud Report
        run: |
          echo "### 🔍 [View full SonarCloud Report](https://sonarcloud.io/project/overview?id=agrisalesa_mlops_boston)" >> $GITHUB_STEP_SUMMARY

  drift-check:
    needs: [build-train-test, sonarcloud-analysis]
    runs-on: ubuntu-latest
    outputs:
      drift: ${{ steps.setout.outputs.drift }}
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install scipy

      - name: Download model artifacts
        uses: actions/download-artifact@v4
        with:
          name: model-artifacts
          path: .

      - name: Ensure logs directory
        run: mkdir -p logs

      - name: Run drift detection
        run: python scripts/04_drift_check.py || true

      - name: Set drift output
        id: setout
        shell: bash
        run: |
          DRIFT=false
          if [ -f logs/drift_report.json ]; then
            DRIFT=$(python -c "import json; r=json.load(open('logs/drift_report.json')); print('true' if r.get('summary',{}).get('drift_detected') else 'false')")
          fi
          echo "drift=$DRIFT" >> "$GITHUB_OUTPUT"

  retrain:
    needs: [build-train-test, drift-check]
    if: needs.build-train-test.result == 'success' && (github.event.inputs.force_retrain == 'true' || needs.drift-check.outputs.drift == 'true')
    runs-on: ubuntu-latest
    outputs:
      updated: ${{ steps.flag.outputs.updated }}
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install xgboost scipy

      - name: Download model artifacts
        uses: actions/download-artifact@v4
        with:
          name: model-artifacts
          path: .

      - name: Retrain model (conditional)
        run: python scripts/03_retrain_if_better.py --force

      - name: Upload updated artifacts
        uses: actions/upload-artifact@v4
        with:
          name: model-artifacts-updated
          path: |
            models/
            data/processed/housing_clean.csv
            data/provenance.json

      - name: Flag updated artifacts
        id: flag
        run: echo "updated=true" >> "$GITHUB_OUTPUT"

  docker-image:
    if: ${{ always() }}
    needs: [build-train-test, retrain]
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Debug job dependencies
        run: |
          echo "needs.retrain.result=${{ needs.retrain.result }}"
          echo "needs.retrain.outputs.updated=${{ needs.retrain.outputs.updated }}"

      - name: Download updated artifacts (if retrained)
        if: needs.retrain.result == 'success' && needs.retrain.outputs.updated == 'true'
        uses: actions/download-artifact@v4
        with:
          name: model-artifacts-updated
          path: .

      - name: Download baseline artifacts (fallback)
        if: needs.retrain.result != 'success' || needs.retrain.outputs.updated != 'true'
        uses: actions/download-artifact@v4
        with:
          name: model-artifacts
          path: .

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Build and push Docker image
        uses: docker/build-push-action@v6
        with:
          context: .
          push: true
          tags: ghcr.io/${{ github.repository }}:latest
