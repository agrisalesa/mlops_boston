# ğŸ§  Proyecto MLOps â€” Boston Housing

**Autor:** AndrÃ©s Grisales Ardila  

**DescripciÃ³n:**  
ImplementaciÃ³n completa de un flujo MLOps de extremo a extremo para un modelo de regresiÃ³n usando el dataset *Boston Housing*.  
Incluye trazabilidad de datos, validaciÃ³n robusta, entrenamiento con mÃºltiples modelos, selecciÃ³n automÃ¡tica del mejor modelo, despliegue mediante una API Flask, y pipeline automatizado de CI/CD con GitHub Actions y Docker.

---

## ğŸ§© Estructura del proyecto

```
mlops_boston/
â”‚
â”œâ”€â”€ .github/workflows/          # Pipeline CI/CD (mlops.yml)
â”œâ”€â”€ app/                        # API Flask (endpoints health y predict)
â”œâ”€â”€ data/                       # Datos crudos, procesados y metadatos
â”œâ”€â”€ logs/                       # Registros de ejecuciÃ³n y validaciÃ³n
â”œâ”€â”€ models/                     # Modelos y preprocesadores entrenados
â”œâ”€â”€ scripts/                    # Entrenamiento, validaciÃ³n y pruebas
â”‚
â”œâ”€â”€ .dockerignore               # Archivos y carpetas ignoradas por Docker
â”œâ”€â”€ Dockerfile                  # Imagen de despliegue (Flask + modelo)
â”œâ”€â”€ DATA_PROVENANCE.md          # Hash SHA256 del dataset original
â”œâ”€â”€ requirements.txt            # Dependencias del proyecto
â””â”€â”€ README.md                   # DocumentaciÃ³n principal del proyecto
```

---

## âš™ï¸ 1. Entorno y dependencias

Crear un entorno virtual e instalar dependencias:

```bash
python -m venv .venv
source .venv/bin/activate    # En Linux/Mac
.venv\Scripts\activate     # En Windows

pip install -r requirements.txt
```

---

## ğŸ§  2. Entrenamiento del modelo

Ejecutar el pipeline de entrenamiento (ejemplo desde `scripts/train.py`):

```bash
python scripts/train.py
```

Esto genera:
- `models/best_model.pkl` â†’ modelo entrenado y optimizado  
- `models/preprocessor.pkl` â†’ transformaciones de datos  
- Logs de validaciÃ³n y mÃ©tricas en `/logs`  

---

## ğŸŒ 3. API Flask â€” Servidor del modelo

El archivo principal `app/main.py` define los **endpoints**:

```python
@app.route('/health', methods=['GET'])
def health():
    return jsonify({
        "best_model": True,
        "preprocessor": True,
        "schema": True,
        "status": "ok"
    })

@app.route('/predict', methods=['POST'])
def predict():
    data = request.get_json()
    df = pd.DataFrame([data])
    X = preprocessor.transform(df)
    prediction = model.predict(X)
    return jsonify({"prediction": float(prediction[0])})
```

### ğŸ”¹ Ejecutar localmente

```bash
python app/main.py
```

Verifica los endpoints:

- `GET http://127.0.0.1:8000/health`
- `POST http://127.0.0.1:8000/predict` con JSON de entrada.

Ejemplo de cuerpo JSON:
```json
{
  "CRIM": 0.1,
  "ZN": 18,
  "INDUS": 2.31,
  "CHAS": 0,
  "NOX": 0.538,
  "RM": 6.575,
  "AGE": 65.2,
  "DIS": 4.09,
  "RAD": 1,
  "TAX": 296,
  "PTRATIO": 15.3,
  "B": 396.9,
  "LSTAT": 4.98
}
```

---

## ğŸ³ 4. Despliegue con Docker

**Dockerfile:**
```dockerfile
FROM python:3.9-slim
WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .
EXPOSE 8000

CMD ["gunicorn", "-w", "2", "-b", "0.0.0.0:8000", "app.main:app"]
```

**.dockerignore:**
```
__pycache__/
*.pyc
*.pkl
*.log
.venv/
data/
logs/
```

Construir y ejecutar la imagen:

```bash
docker build -t mlops_boston .
docker run -p 8000:8000 mlops_boston
```

---

## âš™ï¸ 5. CI/CD con GitHub Actions

Archivo: `.github/workflows/mlops.yml`

```yaml
name: mlops-ci

on:
  push:
    branches: [ "main" ]

jobs:
  build-train-test:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.9"

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Train model
        run: python scripts/train.py

      - name: Save model artifact
        uses: actions/upload-artifact@v3
        with:
          name: model-artifacts
          path: models/

  docker:
    needs: build-train-test
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v2
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Build and push Docker image
        uses: docker/build-push-action@v3
        with:
          context: .
          push: true
          tags: ghcr.io/${{ github.repository }}:latest
```

---

## ğŸš€ 6. Despliegue en GitHub Codespaces

Puedes ejecutar el contenedor directamente en tu entorno Codespaces.  
El puerto **8000** debe marcarse como **â€œPublicâ€** y abrirlo desde el panel *Ports*.

### Para probar:

- Endpoint de salud:  
  `GET https://<tu_codespace>.github.dev/health`  
- Endpoint de predicciÃ³n:  
  `POST https://<tu_codespace>.github.dev/predict`

---

## ğŸ” 7. Conceptos clave aprendidos

| Concepto | ExplicaciÃ³n |
|-----------|-------------|
| **Puerto 8000** | Es la â€œpuertaâ€ por donde Flask escucha las peticiones HTTP. |
| **Endpoint** | Es la â€œrutaâ€ o funciÃ³n especÃ­fica del servidor que responde a una URL. |
| **Flask** | Microframework de Python que convierte funciones en servicios web. |
| **Docker** | Empaqueta el proyecto con todas sus dependencias en un contenedor reproducible. |
| **GitHub Actions** | Automatiza el entrenamiento, pruebas y publicaciÃ³n del contenedor. |

---

## ğŸ§­ 8. Flujo general del proyecto

1ï¸âƒ£ ValidaciÃ³n y preprocesamiento de datos  
2ï¸âƒ£ Entrenamiento con mÃºltiples modelos  
3ï¸âƒ£ SelecciÃ³n del mejor modelo  
4ï¸âƒ£ SerializaciÃ³n (`joblib`) de modelo y preprocesador  
5ï¸âƒ£ Despliegue con Flask  
6ï¸âƒ£ ContenerizaciÃ³n con Docker  
7ï¸âƒ£ AutomatizaciÃ³n con GitHub Actions  
8ï¸âƒ£ EjecuciÃ³n y prueba en Codespaces  

---

## ğŸ“ˆ 9. Ejemplo de flujo en producciÃ³n (visual)

El flujo de peticiones hacia la API Flask:

![Diagrama de flujo API Flask](A_diagram_in_a_digital_vector_graphic_format_illus.png)

---

## ğŸ 10. PrÃ³ximos pasos sugeridos

- Migrar de **Flask** a **FastAPI** para documentaciÃ³n automÃ¡tica.  
- Incluir monitoreo de predicciones con MLflow o EvidentlyAI.  
- Desplegar en un entorno gestionado (AWS, Azure o Google Cloud).  

---

ğŸ“Œ **Repositorio:** [https://github.com/agrisalesa/mlops_boston](https://github.com/agrisalesa/mlops_boston)  
ğŸ“¦ **Imagen Docker:** `ghcr.io/agrisalesa/mlops_boston:latest`  
